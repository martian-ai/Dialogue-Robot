# Transformer-XL

## The motivation for Transformer-XL.
é¦–å…ˆï¼Œä¸ºä»€ä¹ˆä¼šæå‡ºtransformerXLå‘¢ï¼Œå®ƒçš„æå‡ºä¸»è¦æ˜¯ä¸ºäº†è§£å†³transformerçš„é—®é¢˜ã€‚æˆ‘ä»¬é¦–å…ˆå…ˆåˆ†æä¸€ä¸‹RNNä»¥åŠTransformerçš„ä¼˜ç¼ºç‚¹ã€‚
- RNN
  - ä¼˜ç‚¹ï¼š
    - æ”¯æŒå¯å˜é•¿
    - æ”¯æŒè®°å¿†
    - æœ‰åºåˆ—é¡ºåºå…³ç³»
  - ç¼ºç‚¹ï¼š
    - gradient vanish
    - è€—æ—¶ï¼Œæ— æ³•å¹¶è¡Œ
- Transformer
  - ä¼˜ç‚¹ï¼š
    - å¹¶è¡Œ
    - è€ƒè™‘åˆ°sequenceçš„long term dependencyä¿¡æ¯ï¼ˆç›¸å¯¹äºRNNï¼‰
    - å¯è§£é‡Šæ€§

  - ç¼ºç‚¹ï¼š
    - å¥å­ä¸å¥å­ä¹‹é—´çš„å…³ç³»
    - ç©ºé—´å ç”¨å¤§ï¼ˆå› ä¸ºæˆ‘æ¯ä¸ªencoderçš„score matrixï¼ˆsequenceLen*sequecenLenæ˜¯$N^2$çš„ç©ºé—´å¤æ‚åº¦(BOOOOM!ğŸ’¥)
    å¦‚ä¸‹å›¾
    ![](http://blog-picture-bed.oss-cn-beijing.aliyuncs.com/e6cd1de1a51866eed26229f0d0a7ba59.png)
    ![](http://blog-picture-bed.oss-cn-beijing.aliyuncs.com/445c0be69eb60aa340c770da4e97e8e6.png)
    - batch sizeä¹Ÿä¸èƒ½å¾ˆå¤§
  - è§£å†³çš„æ–¹æ¡ˆï¼Œå°†æ–‡ç« documnetåˆ‡æˆsegmentsï¼Œå–‚ç»™transformer
  ![](http://blog-picture-bed.oss-cn-beijing.aliyuncs.com/724c1f23966930d26a817b9e63214aa2.png)
  ä½†æ˜¯segmentä¹‹é—´æ²¡æœ‰ä¿¡æ¯ä¼ é€’ï¼ŒThis problem is called context fragmentation.ï¼

  > The daughter had a nice umbrella that her mother gave her.
  `daughter` and `her` are in different segment
  ![](http://blog-picture-bed.oss-cn-beijing.aliyuncs.com/922db1d2707e08b212ecedd7569242dc.png)
  å‰åå¥å°±ä¸èƒ½å¤Ÿäº†è§£è¿™ä¸ªé›¨ä¼æ˜¯ä»–å¦ˆå¦ˆç»™çš„

é‚£ä¹ˆå¦‚æœè§£å†³è¿™ä¸ªé—®é¢˜å‘¢ï¼Ÿæˆ‘ä»¬å…¶å®åªéœ€è¦ä½¿ç”¨RNNçš„ hidden stateæ¥è§£å†³ä¿¡æ¯çš„ä¼ é€’ï¼Œæˆ‘ä»¬åœ¨ä¸åŒçš„segmentä¹‹é—´ä¼ å…¥ä¼ é€’memoryä¿¡æ¯ã€‚
![](http://blog-picture-bed.oss-cn-beijing.aliyuncs.com/90212426d6b30a7b6980086078c7490c.png)
![](http://blog-picture-bed.oss-cn-beijing.aliyuncs.com/6b9c243803fb86923010ae973f28e450.png)

## Transformer-XL: the proposed solution: Basic idea.
æ‰€ä»¥transformerï¼šï¼ˆ1+2: positional embeddingï¼Œ 3: stacks of encodersï¼‰

![](http://blog-picture-bed.oss-cn-beijing.aliyuncs.com/a23007c68ea1202b673b4a0e763cd6af.png)

å‡çº§å˜æˆä¸‹å›¾ï¼ˆæ³¨æ„æ˜¯embedding/hidden outputçš„concatï¼Œä¸æ˜¯scoreçš„concatï¼‰

![](http://blog-picture-bed.oss-cn-beijing.aliyuncs.com/d4c685ff332774313c38f0378a589c09.png)

å¯ä»¥ç®€å•çš„ç†è§£ transformerXL = transformer + RNN => segment-wiseçš„RNN
[Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context](https://arxiv.org/pdf/1901.02860)
![](http://blog-picture-bed.oss-cn-beijing.aliyuncs.com/8852e25c0b80d8ce3ad586c218c23315.png)

```
å¯¹äºæ‰€æœ‰çš„encoder i é™¤äº†æœ€åä¸€ä¸ªencoder
  Set h_{-1,i } ä¸ºå…¨0çŸ©é˜µï¼ŒçŸ©é˜µå½¢çŠ¶å’Œä¹‹åçš„segmentçš„outputçŸ©é˜µå½¢çŠ¶ä¸€è‡´
å½“æˆ‘ä»¬è®¡ç®— segment 0æ—¶:
  å¯¹äºæ‰€æœ‰çš„encoder i é™¤äº†æœ€åä¸€ä¸ªencoder:
    Combine the saved hidden states: h_{-1,i-1} and h_{0,i-1}.
  å¯¹äºæ‰€æœ‰çš„encoder i é™¤äº†æœ€åä¸€ä¸ªencoder:
    Make a copy of its output h_{0,i }(hidden state).
å½“æˆ‘ä»¬è®¡ç®—segment 1æ—¶:
  å¯¹äºæ‰€æœ‰çš„encoder i é™¤äº†æœ€åä¸€ä¸ªencoder:
    Combine the saved hidden states: h_{0,i-1} and h_{1,i-1}.
  å¯¹äºæ‰€æœ‰çš„encoder i é™¤äº†æœ€åä¸€ä¸ªencoder:
    Make a copy of its output h_{1,i }(hidden state).
â€¦
å½“æˆ‘ä»¬è®¡ç®— segment t:
  å¯¹äºæ‰€æœ‰çš„encoder i é™¤äº†æœ€åä¸€ä¸ªencoder:
    Combine the saved hidden states: h_{t-1,i-1} and h_{t,i-1}.
  å¯¹äºæ‰€æœ‰çš„encoder i é™¤äº†æœ€åä¸€ä¸ªencoder:
    Make a copy of its output h_{t,i }(hidden state).
* This shape will be (batch_size, segment_len, emb_dim).
```

### combine hidden states
![](http://blog-picture-bed.oss-cn-beijing.aliyuncs.com/48e92a26d7a3f557d86b844a4b22e8e1.png)
æˆ‘ä»¬æ¥çœ‹çœ‹å¦‚ä½•`Combine the saved hidden states: h_{t-1,i-1} and h_{t,i-1}.`ï¼Œå…¶å®å¾ˆç®€å•ï¼Œå°±æ˜¯ç›´æ¥ç›´æ¥åœ¨ segment è¿™ä¸ªç»´åº¦ä¸Šé¢concatèµ·æ¥ã€‚
![](http://blog-picture-bed.oss-cn-beijing.aliyuncs.com/2d6e82257da07322a8ad2583d01656b0.png)

åŸæœ¬çš„è¾“å‡ºshape(batch\_size, segment\_len, emb\_dim), ç°åœ¨çš„combinateä¹‹åï¼Œè¾“å‡ºå˜æˆäº†(batch\_size, 2*segment\_len, emb\_dim)

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨è®­ç»ƒçš„æ—¶å€™ï¼Œæˆ‘ä»¬æ˜¯ä¸ç”¨åå‘ä¼ æ’­æ›´æ–°æˆ‘ä»¬çš„memeryçš„ï¼Œæˆ‘ä»¬çš„memoryæ˜¯ä¹‹å‰çš„sequenceçš„ç»“æœï¼Œæˆ‘ä»¬å¯ä»¥åœ¨pytorchä¸­è®¾ç½®`.requires_grad=False`ã€‚

### how to compute self-attention
åœ¨åšself-attentionçš„æ—¶å€™ï¼Œè¾“å…¥çš„$h_{t,i}$ä½œä¸ºfrom\_tensor å’Œto\_tensorè‡ªå·±attend to è‡ªå·±ï¼Œ$h_{t,i}$ç”¨æ¥äº§ç”ŸQï¼ŒKï¼ŒVçŸ©é˜µï¼Œä½†æ˜¯åœ¨transformer-XLä¸­ï¼Œæˆ‘ä»¬çš„query Qç”¨çš„ä»ç„¶æ˜¯æˆ‘ä»¬çš„è¾“å…¥$h_{t,i}$äº§ç”Ÿï¼Œä½†æ˜¯Kï¼ŒVï¼Œéƒ½æ˜¯ç”¨çš„æ˜¯$conc\_h_{t,i}$, å…¶ä¸­$conc\_h_{t,i}= [h_{t-1},i;h_{t,i}]$
![](http://blog-picture-bed.oss-cn-beijing.aliyuncs.com/bafada54b454382239691525f950e9d8.png)

![](http://blog-picture-bed.oss-cn-beijing.aliyuncs.com/f5fedf7a540ccec1d90514bb6a6fdd42.png)

softmax å‡ºæ¥çš„ç»“æœï¼š
![](http://blog-picture-bed.oss-cn-beijing.aliyuncs.com/3dafddcdc3cdba028382d7a20e49c4d0.png)

å¯¹äºdecoderæ¥è¯´æˆ‘ä»¬éœ€è¦åŠ ä¸Šä¸€ä¸ªlook-ahead maskï¼Œå°±å’Œtrasnformer

![](http://blog-picture-bed.oss-cn-beijing.aliyuncs.com/1c8b926d22b357fd9611abdfc4230347.png)

æˆ‘ä»¬æ¯æ¬¡éƒ½åªconcatå‰ä¸€æ¬¡çš„$h_{t-1,i}$ï¼Œè¿™æ˜¯å› ä¸ºæˆ‘ä»¬è®¤ä¸ºæˆ‘ä»¬å‰ä¸€æ¬¡çš„è¾“å‡ºå·²ç»åŒ…æ‹¬äº†ä¹‹å‰æ‰€æœ‰çš„ä¿¡æ¯äº†ã€‚
## Absolute Positional Encoding & Memory:
![](http://blog-picture-bed.oss-cn-beijing.aliyuncs.com/94add13483e2a6facbd66470be37804d.png)


å¦‚æœæˆ‘ä»¬ç»§ç»­ä½¿ç”¨ä¹‹å‰çš„absolute positing encodingçš„è¯ï¼Œå¯¹äºæ‰€æœ‰çš„sequenceçš„åºåˆ—ï¼Œåªè¦è¿™ä¸ªå­—åœ¨åºåˆ—ä¸­çš„ä½ç½®ä¸€æ ·çš„è¯ï¼Œå®ƒçš„position encodingä¹Ÿä¼šä¸€æ ·ï¼Œè¿™æ ·çš„è¯ï¼Œå¯¹äºæˆ‘ä»¬concatä¹‹åçš„è¾“å‡ºï¼Œæˆ‘ä»¬æ— æ³•åŒºåˆ«æ¯ä¸ªå­—çš„ä½ç½®ã€‚

å¦‚ä¸‹å›¾ï¼š`The`å’Œ`that`çš„position encodingå®Œå…¨ä¸€æ ·ï¼Œæ¨¡å‹æ— æ³•åŒºåˆ†ä¸¤è€…ä½ç½®åŒºåˆ«ã€‚

![](http://blog-picture-bed.oss-cn-beijing.aliyuncs.com/1bd6566e9cdef43d251fd61d14e1dd67.png)

æ‰€ä»¥Transformer-XL é¦–å…ˆåˆ†æäº†position encodingåœ¨è®¡ç®—ä¸­çš„ä½œç”¨ï¼Œç„¶åæ ¹æ®è¿™ä¸ªç»“æœå°†äº¤äº’é¡¹è½¬åŒ–ä¸ºrelative position encodingã€‚

- åˆ†æäº†æ¯ä¸ªposition encodingåœ¨è®¡ç®—ä¸­çš„ä½œç”¨
  - $E+P$: embeddimng+position encoding
  - $(E+P)_{i, .}W^Q$: Q
  - $(W^K)^T(E+P)^T_{.,j}$: $K^T$
  ![](http://blog-picture-bed.oss-cn-beijing.aliyuncs.com/fc8448461cc9ba4b63ba34032262e691.png)
  The notation $(i, â€¢)$ refers to the entire row $i$ and $(â€¢, j)$ to the entire column $j$ .
  ç»è¿‡è®¡ç®—ï¼Œè¿™ä¸ªå¼å­å¯ä»¥åˆ†ä¸º4é¡¹ã€‚

  - a) è¿™ä¸€é¡¹ä¸­æ²¡æœ‰åŒ…å«$P$ ä½ç½®ä¿¡æ¯ï¼Œä»£è¡¨çš„æ˜¯åœ¨ç¬¬ $i$ è¡Œçš„å­—åº”è¯¥å¯¹ç¬¬ $j$ åˆ—çš„å­—æä¾›å¤šå¤§çš„æ³¨æ„åŠ›ã€‚è¿™æ˜¯ä¸ç®¡ä»–ä»¬ä¸¤ä¸ªå­—çš„ä½ç½®ä¿¡æ¯çš„ã€‚

  - b) è¿™ä¸€é¡¹æ•è·çš„æ˜¯æ¨¡å‹çš„global attentionï¼ŒæŒ‡çš„æ˜¯ä¸€ä¸ªå­—åœ¨position i åº”è¯¥è¦å¯¹ position j ä»˜å‡ºå¤šå¤§çš„æ³¨æ„åŠ›ã€‚ä¾‹å¦‚ä¸¤ä¸ªå­—çš„ä½ç½®è¶Šè¿œï¼ŒæœŸæœ›å®ƒä»¬ä¹‹é—´çš„æ³¨æ„åŠ›è¶Šå°ã€‚

  - c) è¿™ä¸€é¡¹æ•è·çš„æ˜¯åœ¨row içš„å­—å¯¹å…¶ä»–ä½ç½®çš„å…³æ³¨ä¿¡æ¯ï¼Œä¾‹å¦‚åœ¨position iæ˜¯ä¸€ä¸ªå­—"ç‹—"ï¼Œ åº”è¯¥è¦å¯¹j=i-1 è¿™ä¸ªä½ç½®ç‰¹åˆ«æ³¨æ„ï¼Œå¦åˆ™å¯èƒ½å‡ºç°j=i-1æ˜¯â€œçƒ­â€ï¼Œ å‡ºç°æ˜¯â€œçƒ­ç‹—â€çš„æƒ…å†µã€‚

  - d) è¿™ä¸ªæ˜¯c) çš„é€†å‘è¡¨ç¤ºï¼ŒæŒ‡çš„æ˜¯jçš„å­—è¦pay attention to ä½ç½®içš„å­—ã€‚


- æ ¹æ®è¿™ä¸ªè§‚æµ‹ï¼Œè½¬åŒ–relative position
  é€šè¿‡äº†è§£äº†æ¯ä¸€é¡¹çš„æ„ä¹‰ï¼Œæˆ‘ä»¬äº†è§£äº†ä¸¤ä¸ªå­—çš„ç›¸å¯¹ä½ç½®å¯¹è¿™ä¸ªscoreçš„ä½œç”¨ã€‚æˆ‘ä»¬å°†
  b), c) and d) æ›¿æ¢ä¸ºå¦‚ä¸‹å¼å­ã€‚

  ![](http://blog-picture-bed.oss-cn-beijing.aliyuncs.com/0903e5acf67612ca816264c85458ddad.png)

  æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸»è¦çš„å˜åŒ–
  - æˆ‘ä»¬å°†ä½¿ç”¨çš„æ˜¯ç›¸å¯¹çš„position encoding i.e. å–æ¶ˆ $P_{â€¢, j}$ è€Œé‡‡ç”¨ $P_{â€¢, i â€” j}$ ç›¸å¯¹ä½ç½®ã€‚
  - æ¯æ¬¡ä½¿ç”¨ $P_{â€¢, i â€” j}$ æˆ‘ä»¬éƒ½å°† $W^k$ æ›¿æ¢ä¸º $WË†R$ (ä¸¤è€…çš„å½¢çŠ¶ç›¸åŒ)ã€‚è¿™æ˜¯ä¸ºäº†åŒºåˆ«$W^k$ï¼ˆä»ä½¿ç”¨ï¼‰ å’Œ $WË†R$ï¼Œä½¿å¾—ä¸¤è€…å¯ä»¥å„è‡ªæ•è·æœ‰æ„ä¹‰çš„ä½ç½®ä¿¡æ¯è€Œä¸ä¼šç›¸äº’å¹²é¢„ï¼Œå› ä¸º$W^R$å’Œ$P_{â€¢, i â€” j}$ç›¸åŒ¹é…ï¼Œè€Œ$W^K$å’Œ$E^T_{â€¢,j}$ åƒå¯¹äºã€‚
  - $P_{i,â€¢}W^Q$è¿™ä¸€é¡¹è¢«æ›¿ä»£ä¸º $u$ å’Œ $v$ ï¼Œè¿™ä¸¤ä¸ªå‘é‡çš„ç»´åº¦ä¸º (1, d_k)ã€‚å› ä¸ºæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯ç›¸å¯¹ä½ç½®ç¼–ç ï¼Œæ‰€ä»¥æˆ‘ä»¬å¹¶ä¸éœ€è¦æä¾›ç»å¯¹ä½ç½®$i$ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ç›´æ¥æŠŠæ•´é¡¹æ›¿æ¢æ‰ã€‚è¿™è¾¹ä½¿ç”¨ä¸¤ä¸ªå‘é‡çš„åŸå› æ˜¯å› ä¸ºä¸€é¡¹æ˜¯æ›´æ¢äº†ç›¸å¯¹ä½ç½®(b)ï¼Œä¸€é¡¹æ²¡æœ‰(d)ï¼Œæ‰€ä»¥è¿™æ ·èƒ½å¤Ÿfocus on the general position and the position given the word we attend to as its the case of u and v respectively.ï¼ˆè¿™è¾¹æ²¡æœ‰éå¸¸ç†è§£ï¼‰


  æ‰€ä»¥$(QK^T)_{i,j}$çš„å…¬å¼è¢«æ›¿æ¢ä¸ºï¼š
  \begin{equation}
  (QK^T)_{i,j} = E_{i,â€¢}W^Q(W^K)^TE^T_{â€¢,j}+u(W^R)^TP^T_{â€¢,i-j}+E_{i,â€¢}W^Q(W^R)^TP^T_{â€¢,i-j}+v(W^K)^TE^T_{â€¢,j}
  \end{equation}


## summary
- Memory between segments
- Change from Absolute to Relative Positional Encoding.

## åº”ç”¨å’Œä¸è¶³
æœ€ä¸»è¦çš„åº”ç”¨æ˜¯ä»–ç”¨åœ¨XLNETä¸Š
ä¸è¶³çš„è¯ï¼Œmemoryçš„å…¬å¼çš„è®¾è®¡ä¸å¥½ï¼Œç›´æ¥concatã€‚
ä»¥åŠrelative position encodingçš„è®¾è®¡ä¹Ÿä¸æ˜¯å¾ˆåˆç†ã€‚

## ref
[Dissecting Transformer-XL](https://medium.com/@mromerocalvo/dissecting-transformer-xl-90963e274bd7)

[Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context](https://arxiv.org/pdf/1901.02860)

[XLNETè¯¦è§£](https://www.bilibili.com/video/av73657563?from=search&seid=11939921467334417999)