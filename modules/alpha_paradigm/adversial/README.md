## Adversial Training

### 对抗样本

### 对抗

+ Fast 

+ Project
    + 简单的说，就是“小步走，多走几步”，如果走出了扰动半径为 [公式] 的空间，就映射回“球面”上，以保证扰动不要过大


## Virtual Adversarial Training
+ Virtual Adversarial Training:A Regularization Method for Supervised and Semi-Supervised Learning
+ 半监督学习的精髓大概率就在于正则化(一致性)上面，vat是一种**基于熵最小化出发的正则方法**
+ 出发点在于，要学习一致性那就得添加扰动，通常添加的随机扰动无法模拟各种复杂情况的输入，所以需要**添加合适的扰动**
+ 因此根据一定的理论基础提出了如何找到合适的扰动，以及计算扰动的方法。我们记模型的损失函数为 $J(\theta ; x ; y)$, 其中负梯度方向 -$J(\theta ; x ; y)$ , 为了使 $\hat x$对模型的输出分布产生最大的改变，正梯度方向也就是模型梯度下降最慢的方向定为扰动方向，这就是vat需要添加扰动的方向

### 思路
+ vat的引入了虚拟对抗方向的概念，即扰动的方向，在输入数据中加入此方向上的扰动可以最大程度的影响模型分类输出概率分布，根据虚拟对抗方向的定义，可以在不使用监督信号的情况下，量化模型在每个输入点的局部各向异性，将Local Distributional Smoothness (LDS)定义为针对虚拟对抗方向的模型基于散度的分布鲁棒性，提出了一种新颖的使用有效的近似值，以最大程度地提高模型的熵，同时在每个训练输入数据点上提升模型的LDS，此方法成为vat。

### 优点
+ 适用于半监督学习任务
+ 适用于任何我们可以评估输入和参数梯度的参数模型
+ 超参数数量少
+ 参数化不变正则化