{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSCTS\n",
    "+ large scale Chinese short text summarization dataset)\n",
    "+ 中文社交媒体文本，LCSTS数据集的特点是文本篇幅较短，并且存在噪声\n",
    "+ 训练集大小\t2400000\n",
    "+ 验证集大小\t10000\n",
    "+ 测试集大小\t1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/sunhongchao/miniconda3/envs/bot-mvp/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer \n",
    "\n",
    "model = None\n",
    "tokenizer = None\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" \n",
    "\n",
    "with torch.no_grad():\n",
    "    # model_ckpt = \"google/pegasus-cnn_dailymail\" \n",
    "    model_ckpt = '../../../resources/embedding/google_pegasus-cnn-dm'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_ckpt) \n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/sunhongchao/miniconda3/envs/bot-mvp/lib/python3.6/site-packages/pandas/io/parsers.py:767: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return read_csv(**locals())\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "# from transformers import BertTokenizer\n",
    "# TokenModel = \"../../../resources/embedding/t5-large\"\n",
    "# tokenizer = BertTokenizer.from_pretrained(TokenModel)\n",
    "\n",
    "max_input_length = 128\n",
    "max_target_length = 32\n",
    " \n",
    "lcsts_part_1=pd.read_table('../../../resources/dataset/lscts/DATA/PART_II.txt', header=None,\n",
    "                           warn_bad_lines=True, error_bad_lines=False, sep='<[/d|/s|do|su|sh][^a].*>', encoding='utf-8') # PART I  too big, use PART II instead\n",
    "lcsts_part_1=lcsts_part_1[0].dropna()\n",
    "lcsts_part_1=lcsts_part_1.reset_index(drop=True)\n",
    "lcsts_part_1=pd.concat([lcsts_part_1[1::2].reset_index(drop=True), lcsts_part_1[::2].reset_index(drop=True)], axis=1)\n",
    "lcsts_part_1.columns=['document', 'summary']\n",
    " \n",
    "lcsts_part_2=pd.read_table('../../../resources/dataset/lscts/DATA/PART_II.txt', header=None,\n",
    "                           warn_bad_lines=True, error_bad_lines=False, sep='<[/d|/s|do|su|sh][^a].*>', encoding='utf-8')\n",
    "lcsts_part_2=lcsts_part_2[0].dropna()\n",
    "lcsts_part_2=lcsts_part_2.reset_index(drop=True)\n",
    "lcsts_part_2=pd.concat([lcsts_part_2[1::2].reset_index(drop=True), lcsts_part_2[::2].reset_index(drop=True)], axis=1)\n",
    "lcsts_part_2.columns=['document', 'summary']\n",
    " \n",
    "dataset_train = Dataset.from_dict(lcsts_part_1)\n",
    "dataset_valid = Dataset.from_dict(lcsts_part_2)\n",
    "\n",
    "d_len = [len(tokenizer.encode(s['document'])) for s in dataset_train] \n",
    "s_len = [len(tokenizer.encode(s['summary'])) for s in dataset_train] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x252 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3.5), sharey=True)\n",
    "axes[0].hist(d_len, bins=20, color=\"C0\", edgecolor=\"C0\") \n",
    "axes[0].set_title(\"Dialogue Token Length\") \n",
    "axes[0].set_xlabel(\"Length\") \n",
    "axes[0].set_ylabel(\"Count\") \n",
    "axes[1].hist(s_len, bins=20, color=\"C0\", edgecolor=\"C0\") \n",
    "axes[1].set_title(\"Summary Token Length\") \n",
    "axes[1].set_xlabel(\"Length\") \n",
    "plt.tight_layout() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_function(examples):\n",
    "#     inputs = [str(doc) for doc in examples[\"document\"]]\n",
    "#     model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "#     inputs = [str(doc) for doc in examples[\"summary\"]]\n",
    "#     # Setup the tokenizer for targets\n",
    "#     with tokenizer.as_target_tokenizer():\n",
    "#         labels = tokenizer(inputs, max_length=max_target_length, truncation=True)\n",
    " \n",
    "#     model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "#     return model_inputs\n",
    "\n",
    "# tokenized_datasets_t = dataset_train.map(preprocess_function, batched=True)\n",
    "# tokenized_datasets_v = dataset_valid.map(preprocess_function, batched=True)\n",
    " \n",
    "# tokenized_datasets = datasets.DatasetDict({\"train\":tokenized_datasets_t,\"validation\": tokenized_datasets_v})\n",
    "# print(tokenized_datasets)\n",
    "# print(tokenized_datasets['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://xiaosheng.run/2022/03/29/transformers-note-8.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/sunhongchao/miniconda3/envs/bot-mvp/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.157029: 100%|██████████| 1334/1334 [06:03<00:00,  3.67it/s]\n",
      "100%|██████████| 1334/1334 [17:30<00:00,  1.27it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Collections must contain at least 1 sentence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3a84ae16998a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}/{epoch_num}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0mvalid_rouge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m     \u001b[0mrouge_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_rouge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrouge_avg\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_avg_rouge\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-3a84ae16998a>\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(dataloader, model, mode)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecoded_preds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecoded_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrouge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bot-mvp/lib/python3.6/site-packages/rouge/rouge.py\u001b[0m in \u001b[0;36mget_scores\u001b[0;34m(self, hyps, refs, avg, ignore_empty)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_avg_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bot-mvp/lib/python3.6/site-packages/rouge/rouge.py\u001b[0m in \u001b[0;36m_get_avg_scores\u001b[0;34m(self, hyps, refs)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRouge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAVAILABLE_METRICS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                 \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bot-mvp/lib/python3.6/site-packages/rouge/rouge.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(hyp, ref)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mDEFAULT_METRICS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"rouge-1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rouge-2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rouge-l\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     AVAILABLE_METRICS = {\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;34m\"rouge-1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrouge_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrouge_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;34m\"rouge-2\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrouge_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrouge_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;34m\"rouge-l\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bot-mvp/lib/python3.6/site-packages/rouge/rouge_score.py\u001b[0m in \u001b[0;36mrouge_n\u001b[0;34m(evaluated_sentences, reference_sentences, n)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \"\"\"\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluated_sentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_sentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Collections must contain at least 1 sentence.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0mevaluated_ngrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_word_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluated_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Collections must contain at least 1 sentence."
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\"\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import AdamW, get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "from rouge import Rouge\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "max_dataset_size = 200000\n",
    "max_input_length = 128\n",
    "max_target_length = 32\n",
    "train_batch_size = 8\n",
    "test_batch_size = 8\n",
    "learning_rate = 2e-5\n",
    "epoch_num = 3\n",
    "beam_size = 4\n",
    "no_repeat_ngram_size = 2\n",
    "\n",
    "seed = 5\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')\n",
    "\n",
    "class LCSTS(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        self.data = self.load_data(data_file)\n",
    "    \n",
    "    def load_data(self, data_file):\n",
    "        Data = {}\n",
    "        with open(data_file, 'rt', encoding='utf-8') as f:\n",
    "            for idx, line in enumerate(f):\n",
    "                if idx >= max_dataset_size:\n",
    "                    break\n",
    "                items = line.strip().split('!=!')\n",
    "                assert len(items) == 2\n",
    "                Data[idx] = {\n",
    "                    'title': items[0],\n",
    "                    'content': items[1]\n",
    "                }\n",
    "        return Data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# train_data = LCSTS('lcsts_tsv/data1.tsv')\n",
    "# valid_data = LCSTS('lcsts_tsv/data2.tsv')\n",
    "# test_data = LCSTS('lcsts_tsv/data3.tsv')\n",
    "\n",
    "# dataset_train = Dataset.from_dict(lcsts_part_1)\n",
    "# dataset_valid = Dataset.from_dict(lcsts_part_2)\n",
    "\n",
    "train_data = dataset_train\n",
    "valid_data = dataset_valid\n",
    "test_data = dataset_valid\n",
    "\n",
    "model_checkpoint = \"csebuetnlp/mT5_multilingual_XLSum\"\n",
    "model_checkpoint = \"../../../resources/embedding/google_pegasus-cnn-dm\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "model = model.to(device)\n",
    "\n",
    "def collote_fn(batch_samples):\n",
    "    batch_inputs, batch_targets = [], []\n",
    "    for sample in batch_samples:\n",
    "        # print(sample)\n",
    "        batch_inputs.append(sample['document'])\n",
    "        batch_targets.append(sample['summary'])\n",
    "    batch_data = tokenizer(\n",
    "        batch_inputs, \n",
    "        padding=True, \n",
    "        max_length=max_input_length,\n",
    "        truncation=True, \n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            batch_targets, \n",
    "            padding=True, \n",
    "            max_length=max_target_length,\n",
    "            truncation=True, \n",
    "            return_tensors=\"pt\"\n",
    "        )[\"input_ids\"]\n",
    "        batch_data['decoder_input_ids'] = model.prepare_decoder_input_ids_from_labels(labels)\n",
    "        end_token_index = torch.where(labels == tokenizer.eos_token_id)[1]\n",
    "        for idx, end_idx in enumerate(end_token_index):\n",
    "            labels[idx][end_idx+1:] = -100\n",
    "        batch_data['labels'] = labels\n",
    "    return batch_data\n",
    "\n",
    "train_dataloader = DataLoader(dataset_train, batch_size=train_batch_size, shuffle=True, collate_fn=collote_fn)\n",
    "valid_dataloader = DataLoader(dataset_valid, batch_size=test_batch_size, shuffle=False, collate_fn=collote_fn)\n",
    "\n",
    "def train_loop(dataloader, model, optimizer, lr_scheduler, epoch, total_loss):\n",
    "    progress_bar = tqdm(range(len(dataloader)))\n",
    "    progress_bar.set_description(f'loss: {0:>7f}')\n",
    "    finish_batch_num = (epoch-1) * len(dataloader)\n",
    "    \n",
    "    model.train()\n",
    "    for batch, batch_data in enumerate(dataloader, start=1):\n",
    "        batch_data = batch_data.to(device)\n",
    "        outputs = model(**batch_data)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_description(f'loss: {total_loss/(finish_batch_num + batch):>7f}')\n",
    "        progress_bar.update(1)\n",
    "    return total_loss\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "def test_loop(dataloader, model, mode='Test'):\n",
    "    assert mode in ['Valid', 'Test']\n",
    "    preds, labels = [], []\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_data in tqdm(dataloader):\n",
    "        batch_data = batch_data.to(device)\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = model.generate(\n",
    "                batch_data[\"input_ids\"],\n",
    "                attention_mask=batch_data[\"attention_mask\"],\n",
    "                max_length=max_target_length,\n",
    "                num_beams=beam_size,\n",
    "                no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "            ).cpu().numpy()\n",
    "        if isinstance(generated_tokens, tuple):\n",
    "            generated_tokens = generated_tokens[0]\n",
    "        label_tokens = batch_data[\"labels\"].cpu().numpy()\n",
    "\n",
    "        decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        label_tokens = np.where(label_tokens != -100, label_tokens, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(label_tokens, skip_special_tokens=True)\n",
    "\n",
    "        preds += [' '.join(pred.strip()) for pred in decoded_preds]\n",
    "        labels += [' '.join(label.strip()) for label in decoded_labels]\n",
    "    if not preds:\n",
    "        continue\n",
    "    if not labels:\n",
    "        continue\n",
    "    scores = rouge.get_scores(hyps=preds, refs=labels, avg=True)\n",
    "    result = {key: value['f'] * 100 for key, value in scores.items()}\n",
    "    result['avg'] = np.mean(list(result.values()))\n",
    "    print(f\"{mode} Rouge1: {result['rouge-1']:>0.2f} Rouge2: {result['rouge-2']:>0.2f} RougeL: {result['rouge-l']:>0.2f}\\n\")\n",
    "    return result\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=epoch_num*len(train_dataloader),\n",
    ")\n",
    "\n",
    "total_loss = 0.\n",
    "best_avg_rouge = 0.\n",
    "for t in range(epoch_num):\n",
    "    print(f\"Epoch {t+1}/{epoch_num}\\n-------------------------------\")\n",
    "    total_loss = train_loop(train_dataloader, model, optimizer, lr_scheduler, t+1, total_loss)\n",
    "    valid_rouge = test_loop(valid_dataloader, model, mode='Valid')\n",
    "    rouge_avg = valid_rouge['avg']\n",
    "    if rouge_avg > best_avg_rouge:\n",
    "        best_avg_rouge = rouge_avg\n",
    "        print('saving new weights...\\n')\n",
    "        torch.save(model.state_dict(), f'epoch_{t+1}_valid_rouge_{rouge_avg:0.4f}_model_weights.bin')\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('bot-mvp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4632cd8377e743b0d90da04eeb35bbed8ec5d08da721a48d0317015ab0d939e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
