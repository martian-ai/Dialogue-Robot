{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging face eval cnn-dm\n",
    "+ 使用 cnn dailymail 通过 Hugging Face 的各个模型效果评估\n",
    "+ https://github.com/hellotransformers/Natural_Language_Processing_with_Transformers\n",
    "+ https://github.com/hellotransformers/Natural_Language_Processing_with_Transformers/blob/main/chapter6.md\n",
    "+ https://xiaosheng.run/2022/03/29/transformers-note-8.html\n",
    "+ https://github.com/datawhalechina/learn-nlp-with-transformers/blob/main/docs/%E7%AF%87%E7%AB%A04-%E4%BD%BF%E7%94%A8Transformers%E8%A7%A3%E5%86%B3NLP%E4%BB%BB%E5%8A%A1/4.7-%E7%94%9F%E6%88%90%E4%BB%BB%E5%8A%A1-%E6%91%98%E8%A6%81%E7%94%9F%E6%88%90.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets==2.5.2\n",
    "# pip install transformers==4.18.0\n",
    "# !export http_proxy='http://172.19.57.45:3128/'\n",
    "# !export http_proxy='http://172.19.57.45:3128/'\n",
    "# !export http_proxy=''\n",
    "# !export http_proxy=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/sunhongchao/miniconda3/envs/bot-mvp/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Article (excerpt of 500 characters, total length: 3192):\n",
      "\n",
      "(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has n\n",
      "\n",
      "Summary (length: 180):\n",
      "Usain Bolt wins third gold of world championship .\n",
      "Anchors Jamaica to 4x100m relay victory .\n",
      "Eighth gold at the championships for Bolt .\n",
      "Jamaica double up in women's 4x100m relay .\n",
      "(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio Carl Lewis, Michael Johnson and Allyson Felix, not to mention the small matter of six Olympic titles. The relay triumph followed individual successes in the 100 and 200 meters in the Russian capital. \"I'm proud of myself and I'll continue to work to dominate for as long as possible,\" Bolt said, having previously expressed his intention to carry on until the 2016 Rio Olympics. Victory was never seriously in doubt once he got the baton safely in hand from Ashmeade, while Gatlin and the United States third leg runner Rakieem Salaam had problems. Gatlin strayed out of his lane as he struggled to get full control of their baton and was never able to get on terms with Bolt. Earlier, Jamaica's women underlined their dominance in the sprint events by winning the 4x100m relay gold, anchored by Shelly-Ann Fraser-Pryce, who like Bolt was completing a triple. Their quartet recorded a championship record of 41.29 seconds, well clear of France, who crossed the line in second place in 42.73 seconds. Defending champions, the United States, were initially back in the bronze medal position after losing time on the second handover between Alexandria Anderson and English Gardner, but promoted to silver when France were subsequently disqualified for an illegal handover. The British quartet, who were initially fourth, were promoted to the bronze which eluded their men's team. Fraser-Pryce, like Bolt ag\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "# 本地加载\n",
    "dataset = datasets.load_from_disk('../../../resources/dataset/hf_cnn-dm/')\n",
    "\n",
    "sample = dataset[\"train\"][1]\n",
    "print(f\"\"\"\n",
    "Article (excerpt of 500 characters, total length: {len(sample[\"article\"])}):\n",
    "\"\"\")\n",
    "print(sample[\"article\"][:500])\n",
    "print(f'\\nSummary (length: {len(sample[\"highlights\"])}):')\n",
    "print(sample[\"highlights\"])\n",
    "\n",
    "sample_text = dataset[\"train\"][1][\"article\"][:2000]\n",
    "print(sample_text)\n",
    "# We'll collect the generated summaries of each model in a dictionary\n",
    "summaries = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用nltk 对英文的句子进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 101] Network is\n",
      "[nltk_data]     unreachable>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed \n",
    "from transformers import pipeline\n",
    "import torch\n",
    "set_seed(42) \n",
    "\n",
    "def three_sentence_summary(text): \n",
    "\treturn \"\\n\".join(sent_tokenize(text)[:3]) \n",
    "\t\n",
    "summaries[\"baseline\"] = three_sentence_summary(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-generation\", model=\"../../../resources/embedding/gpt2-xl/\") \n",
    "gpt2_query = sample_text + \"\\nTL;DR:\\n\" \n",
    "pipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)\n",
    "\n",
    "summaries[\"gpt2\"] = \"\\n\".join( sent_tokenize(pipe_out[0][\"generated_text\"][len(gpt2_query) :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"../../../resources/embedding/t5-large/\") \n",
    "pipe_out = pipe(sample_text) \n",
    "\n",
    "summaries[\"t5\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"../../../resources/embedding/facebook_bart-large-cnn/\") \n",
    "pipe_out = pipe(sample_text) \n",
    "\n",
    "summaries[\"bart\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pegasus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     pipe = pipeline(\"summarization\", model=\"../../../resources/embedding/google_pegasus-cnn-dm\") \n",
    "#     pipe_out = pipe(sample_text) \n",
    "\n",
    "#     summaries[\"pegasus\"] = pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\")\n",
    "\n",
    "pipe = pipeline(\"summarization\", model=\"../../../resources/embedding/google_pegasus-cnn-dm\") \n",
    "pipe_out = pipe(sample_text) \n",
    "\n",
    "summaries[\"pegasus\"] = pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不同模型效果对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROUND TRUTH\n",
      "Usain Bolt wins third gold of world championship .\n",
      "Anchors Jamaica to 4x100m relay victory .\n",
      "Eighth gold at the championships for Bolt .\n",
      "Jamaica double up in women's 4x100m relay .\n",
      "\n",
      "BASELINE\n",
      "(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay.\n",
      "The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds.\n",
      "The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover.\n",
      "\n",
      "GPT2\n",
      "Nesta, the fastest man in the world.\n",
      "Gatlin, the most successful Olympian ever.\n",
      "Kemar, a Jamaican legend.\n",
      "Shelly-Ann, the fastest woman ever.\n",
      "Bolt, the world's greatest athlete.\n",
      "The team sport of pole vaulting\n",
      "\n",
      "T5\n",
      "usain bolt wins his third gold medal of the world championships in the men's 4x100m relay .\n",
      "the 26-year-old anchored Jamaica to victory in the event in the Russian capital .\n",
      "he has now collected eight gold medals at the championships, equaling the record .\n",
      "\n",
      "BART\n",
      "Usain Bolt wins his third gold of the world championships in Moscow.\n",
      "Bolt anchors Jamaica to victory in the men's 4x100m relay.\n",
      "The 26-year-old has now won eight gold medals at world championships.\n",
      "Jamaica's women also win gold in the relay, beating France in the process.\n",
      "\n",
      "PEGASUS\n",
      "Usain Bolt wins third gold of world championships.\n",
      "Anchors Jamaica to victory in men's 4x100m relay.\n",
      "Eighth gold at the championships for Bolt.\n",
      "Jamaica also win women's 4x100m relay .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"GROUND TRUTH\") \n",
    "print(dataset[\"train\"][1][\"highlights\"]) \n",
    "print(\"\") \n",
    "for model_name in summaries: \n",
    "\tprint(model_name.upper()) \n",
    "\tprint(summaries[model_name]) \n",
    "\tprint(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/users/sunhongchao/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/31e1673407d8789b8f5ddfd979948f6a1de0a6d691426d55fa74a35ffb0c1bdf (last modified on Sat Oct 29 23:06:04 2022) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/users/sunhongchao/.cache/huggingface/modules/datasets_modules/metrics/rouge/0ffdb60f436bdb8884d5e4d608d53dbe108e82dac4f494a66f80ef3f647c104f (last modified on Sat Oct 29 23:10:57 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric \n",
    "import pandas as pd \n",
    "bleu_metric = load_metric(\"sacrebleu\")\n",
    "rouge_metric = load_metric(\"rouge\") # rouge_score==0.0.4 work well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 抽样评估1条"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.232143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5</th>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.486486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bart</th>\n",
       "      <td>0.582278</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>0.506329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.303571  0.090909  0.214286   0.232143\n",
       "gpt2      0.187500  0.000000  0.125000   0.187500\n",
       "t5        0.486486  0.222222  0.378378   0.486486\n",
       "bart      0.582278  0.207792  0.455696   0.506329\n",
       "pegasus   0.866667  0.655172  0.800000   0.833333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference = dataset[\"train\"][1][\"highlights\"] \n",
    "records = [] \n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"] \n",
    "for model_name in summaries: \n",
    "\trouge_metric.add(prediction=summaries[model_name], reference=reference) \n",
    "\tscore = rouge_metric.compute() \n",
    "\trouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "\trecords.append(rouge_dict) \n",
    "pd.DataFrame.from_records(records, index=summaries.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 抽样 1000条 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at ../../../resources/dataset/hf_cnn-dm/test/cache-f551f6b1b06308aa.arrow\n"
     ]
    }
   ],
   "source": [
    "test_sampled = dataset[\"test\"].shuffle(seed=42).select(range(1000)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 抽样评估 1000 条 baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.388071</td>\n",
       "      <td>0.170554</td>\n",
       "      <td>0.247146</td>\n",
       "      <td>0.354972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.388071  0.170554  0.247146   0.354972"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_summaries_baseline(dataset, metric, column_text=\"article\", column_summary=\"highlights\"): \n",
    "    summaries = [three_sentence_summary(text) for text in dataset[column_text]] \n",
    "    metric.add_batch(predictions=summaries, references=dataset[column_summary]) \n",
    "    score = metric.compute() \n",
    "    return score\n",
    "\n",
    "\n",
    "score = evaluate_summaries_baseline(test_sampled, rouge_metric) \n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names) \n",
    "pd.DataFrame.from_dict(rouge_dict, orient=\"index\", columns=[\"baseline\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 抽样评估 1000条 pegasus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [12:58<00:00,  6.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.427098293379068, 'rouge2': 0.2072630667891052, 'rougeL': 0.30511255367162227, 'rougeLsum': 0.3691882873159909}\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" \n",
    "def chunks(list_of_elements, batch_size): \n",
    "\t\"\"\"Yield successive batch-sized chunks from list_of_elements.\"\"\" \n",
    "\tfor i in range(0, len(list_of_elements), batch_size): \n",
    "\t    yield list_of_elements[i : i + batch_size] \n",
    "def evaluate_summaries_pegasus(dataset, metric, model, tokenizer, batch_size=16, device=device, column_text=\"article\", column_summary=\"highlights\"): \n",
    "\tarticle_batches = list(chunks(dataset[column_text], batch_size)) \n",
    "\ttarget_batches = list(chunks(dataset[column_summary], batch_size)) \n",
    "\tfor article_batch, target_batch in tqdm( zip(article_batches, target_batches), total=len(article_batches)): \n",
    "\t\tinputs = tokenizer(article_batch, max_length=1024, truncation=True, padding=\"max_length\", return_tensors=\"pt\") \n",
    "\t\tsummaries = model.generate(input_ids=inputs[\"input_ids\"].to(device), attention_mask=inputs[\"attention_mask\"].to(device), length_penalty=0.8, num_beams=8, max_length=128) \n",
    "\t\tdecoded_summaries = [tokenizer.decode(s, skip_special_tokens=True, clean_up_tokenization_spaces=True) for s in summaries] \n",
    "\t\tdecoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries] \n",
    "\t\tmetric.add_batch(predictions=decoded_summaries, references=target_batch) \n",
    "\tscore = metric.compute() \n",
    "\treturn score\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer \n",
    "\n",
    "model = None\n",
    "tokenizer = None\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_ckpt = \"../../../resources/embedding/google_pegasus-cnn-dm\" \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_ckpt) \n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n",
    "    #model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt) \n",
    "    score = evaluate_summaries_pegasus(test_sampled, rouge_metric, model, tokenizer, batch_size=8) \n",
    "    rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names) \n",
    "    pd.DataFrame(rouge_dict, index=[\"pegasus\"])\n",
    "\n",
    "print(rouge_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
